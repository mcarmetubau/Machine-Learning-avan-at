{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-f75b035c59b4>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.dropna(inplace = True)\n",
      "<ipython-input-1-f75b035c59b4>:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Retard\"] = df[\"ArrDelay\"] > 0\n"
     ]
    }
   ],
   "source": [
    "#- Exercici 1\n",
    "#Agafa el conjunt de dades que vulguis i realitza un pipeline i un gridsearch aplicant l'algorisme de Random Forest.\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "df2 = pd.read_csv(\"DelayedFlights.csv\")\n",
    "df2 = df2.loc[df2.loc[:,'Cancelled'] == 0]\n",
    "df2 = df2.loc[df2.loc[:,'Diverted'] == 0]\n",
    "\n",
    "#df1=df2[['DayOfWeek',  'UniqueCarrier','ActualElapsedTime', 'CRSElapsedTime', 'AirTime', 'ArrDelay',\n",
    "#       'DepDelay', 'Origin','Dest', 'Distance', 'TaxiIn', 'TaxiOut']]\n",
    "df1=df2[['ArrDelay','TaxiIn', 'TaxiOut']]\n",
    "\n",
    "df1.dropna(inplace = True)\n",
    "\n",
    "msk = np.random.rand(len(df1)) < 0.001\n",
    "\n",
    "df = df1[msk]\n",
    "\n",
    "df[\"Retard\"] = df[\"ArrDelay\"] > 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Llibreries necessaries\n",
    "# dades\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Gráfiques\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocesat y modelat\n",
    "# ==============================================================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "# Varis\n",
    "# ==============================================================================\n",
    "import multiprocessing\n",
    "import random\n",
    "from itertools import product\n",
    "from fitter import Fitter, get_common_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuracions matplotlib\n",
    "# ==============================================================================\n",
    "plt.rcParams['image.cmap'] = \"bwr\"\n",
    "#plt.rcParams['figure.dpi'] = \"100\"\n",
    "plt.rcParams['savefig.bbox'] = \"tight\"\n",
    "style.use('ggplot') or plt.style.use('ggplot')\n",
    "\n",
    "# Configuracions warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repartim les dades en Train i test en base ArrDelay i les variables estudiades amb més bons resultats\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "# Repartim les dades en Train i test en base ArrDelay\n",
    "# ==============================================================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        df.drop('ArrDelay', axis = 'columns'),\n",
    "                                        df['ArrDelay'],\n",
    "                                        train_size   = 0.8,\n",
    "                                        random_state = 1234,\n",
    "                                        shuffle      = True\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hiperparámetres (tuning)\n",
    "#Escollir un conjunt de valors pel hiperparametres\n",
    "\n",
    "#grid search: es fa una búsqueda exhaustiva sobre el conjunt de \n",
    "#valors previaments definits per usuari \n",
    "\n",
    "#random search: evaluen valors aletoris dins de limits definits per usuari\n",
    "\n",
    "#Per cada valor (combinació si més un hiperparámetre), entrenar el model i estimar el seu error mitjançant\n",
    "#un metode de validació \n",
    "\n",
    "#Finalment ajusta de nou el model, amb les dades dentranament i els millor hiperparametres trobats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv=RepeatedKFold(n_repeats=3, n_splits=5, random_state=None),\n",
      "                   estimator=Pipeline(steps=[('preprocessing',\n",
      "                                              ColumnTransformer(remainder='passthrough',\n",
      "                                                                transformers=[('numeric',\n",
      "                                                                               Pipeline(steps=[('scaler',\n",
      "                                                                                                StandardScaler())]),\n",
      "                                                                               ['TaxiIn',\n",
      "                                                                                'TaxiOut'])])),\n",
      "                                             ('modelo',\n",
      "                                              RandomForestRegressor())]),\n",
      "                   n_iter=20, n_jobs=3,\n",
      "                   param_distributions={'modelo__max_depth': [None, 3, 5, 10,\n",
      "                                                              20],\n",
      "                                        'modelo__max_features': ['auto', 3, 5,\n",
      "                                                                 7],\n",
      "                                        'modelo__n_estimators': [50, 100, 1000,\n",
      "                                                                 2000]},\n",
      "                   random_state=123, return_train_score=True,\n",
      "                   scoring='neg_root_mean_squared_error')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_modelo__n_estimators</th>\n",
       "      <th>param_modelo__max_features</th>\n",
       "      <th>param_modelo__max_depth</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-53.093464</td>\n",
       "      <td>6.406012</td>\n",
       "      <td>-52.283872</td>\n",
       "      <td>1.569315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_modelo__n_estimators param_modelo__max_features  \\\n",
       "19                       2000                          3   \n",
       "\n",
       "   param_modelo__max_depth  mean_test_score  std_test_score  mean_train_score  \\\n",
       "19                       3       -53.093464        6.406012        -52.283872   \n",
       "\n",
       "    std_train_score  \n",
       "19         1.569315  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Pipeline: preprocesado + modelo\n",
    "# ==============================================================================\n",
    "# Identificación de columnas numéricas y catégoricas\n",
    "numeric_cols = X_train.select_dtypes(include=['float64', 'int']).columns.to_list()\n",
    "\n",
    "\n",
    "# Transformaciones para las variables numéricas\n",
    "numeric_transformer = Pipeline(\n",
    "                        steps=[('scaler', StandardScaler())]\n",
    "                      )\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        ('numeric', numeric_transformer, numeric_cols)\n",
    "                    ],\n",
    "                    remainder='passthrough'\n",
    "                )\n",
    "\n",
    "# Se combinan los pasos de preprocesado y el modelo en un mismo pipeline.\n",
    "pipe = Pipeline([('preprocessing', preprocessor),\n",
    "                 ('modelo', RandomForestRegressor())])\n",
    "\n",
    "# Optimización de hiperparámetros\n",
    "# ==============================================================================\n",
    "# Espacio de búsqueda de cada hiperparámetro\n",
    "\n",
    "param_distributions = {\n",
    "    'modelo__n_estimators': [50, 100, 1000, 2000],\n",
    "    'modelo__max_features': [\"auto\", 3, 5, 7],\n",
    "    'modelo__max_depth'   : [None, 3, 5, 10, 20]\n",
    "}\n",
    "\n",
    "# Búsqueda random grid\n",
    "grid = RandomizedSearchCV(\n",
    "        estimator  = pipe,\n",
    "        param_distributions = param_distributions,\n",
    "        n_iter     = 20,\n",
    "        scoring    = 'neg_root_mean_squared_error',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits = 5, n_repeats = 3),\n",
    "        refit      = True, \n",
    "        verbose    = 0,\n",
    "        random_state = 123,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "grid.fit(X = X_train, y = y_train)\n",
    "print(grid)\n",
    "# Resultados del grid\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(grid.cv_results_)\n",
    "resultados.filter(regex = '(param.*|mean_t|std_t)')\\\n",
    "    .drop(columns = 'params')\\\n",
    "    .sort_values('mean_test_score', ascending = False)\\\n",
    "    .head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El error (rmse) de test es: 54.072309676487286\n"
     ]
    }
   ],
   "source": [
    "# Error de test del modelo final\n",
    "# ==============================================================================\n",
    "modelo_final = grid.best_estimator_\n",
    "predicciones = modelo_final.predict(X = X_test)\n",
    "rmse_rf = mean_squared_error(\n",
    "            y_true  = y_test,\n",
    "            y_pred  = predicciones,\n",
    "            squared = False\n",
    "          )\n",
    "print(f\"El error (rmse) de test es: {rmse_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
